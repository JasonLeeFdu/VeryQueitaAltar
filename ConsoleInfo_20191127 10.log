=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
tensor([[[    inf,     inf,     inf,     inf,     inf,     inf,     inf,
              inf,     inf,     inf,     inf,     inf, -0.1174, -0.2100,
          -0.3441, -0.4265, -0.4878, -0.5839, -0.5949, -0.5528, -0.5343,
          -0.5816, -0.6646, -0.6914, -0.7224, -0.7899, -0.7876, -0.7491,
          -0.8139, -0.8199, -0.8504, -0.8071, -0.8801, -0.8946, -0.8057,
          -0.7243, -0.7412, -0.7418, -0.8642, -0.8457, -0.8759, -0.8223,
          -0.8169, -0.7751, -0.7057, -0.7961, -0.7749, -0.9039, -0.8990,
          -0.7973, -0.7712, -0.8108, -0.8999, -0.8234, -0.8279, -0.8355,
          -0.7939, -0.7922, -0.8179, -0.7595, -0.8069, -0.8318, -0.8050,
          -0.7720, -0.8347, -0.7840, -0.8173, -0.8045, -0.8411, -0.7987,
          -0.8009, -0.8590, -0.7735, -0.8177, -0.7735, -0.7274, -0.7375,
          -0.6978, -0.7008, -0.6277, -0.6641, -0.6418, -0.7141, -0.7494,
          -0.6596, -0.6782, -0.7446, -0.8303, -0.8274, -0.7983, -0.8132,
          -0.8603, -0.7206, -0.8122, -0.8647, -0.9026, -0.8728, -0.7652,
          -0.7684, -0.7390, -0.6476, -0.6396, -0.7051, -0.7444, -0.7753,
          -0.7523, -0.7733, -0.8269, -0.7972, -0.8079, -0.7513, -0.8173,
          -0.7752, -0.7857, -0.8722, -0.8589, -0.9596, -0.8762, -0.8990,
          -0.8910, -0.8716, -0.8773, -0.8329, -0.8263, -0.9272, -0.9855,
          -1.0107, -0.8886, -0.9434, -0.9553, -0.9249, -0.9253, -0.9403,
          -0.9171, -0.8505, -0.8852, -0.7735, -0.7572, -0.7797, -0.7843,
          -0.7526, -0.8130, -0.8520, -0.7935, -0.7868, -0.7717, -0.7722,
          -0.8927, -0.8074, -0.9012, -0.7724, -0.7215, -0.7240, -0.7501,
          -0.6997, -0.7065, -0.7614, -0.6685, -0.6955, -0.7363, -0.7915,
          -0.7631, -0.7777, -0.7815, -0.7691, -0.7476, -0.7250, -0.7458,
          -0.6524, -0.8077, -0.8346, -0.8473, -0.8154, -0.8244, -0.8735,
          -0.8920, -0.8565, -0.8786, -0.8467, -0.9073, -0.8960, -0.9721,
          -0.9598, -0.9324, -0.9604, -0.8925, -0.8768, -0.9090, -0.8964,
          -0.8901, -0.8601, -0.9041, -0.8402, -0.9452, -0.9707, -1.0316,
          -1.0002, -0.8966, -0.9249, -0.9472, -0.9901]]], device='cuda:0',
       grad_fn=<CatBackward>)
torch.Size([1, 1, 201])
tensor(-1.0316, device='cuda:0', grad_fn=<MinBackward1>)
tensor([[[0.9142, 0.8216, 0.6875, 0.6051, 0.5438, 0.4477, 0.4367, 0.4788,
          0.4973, 0.4500, 0.3670, 0.3402, 0.3092, 0.2417, 0.2440, 0.2825,
          0.2177, 0.2117, 0.1812, 0.2245, 0.1515, 0.1370, 0.2259, 0.3073,
          0.2904, 0.2898, 0.1674, 0.1859, 0.1557, 0.2093, 0.2147, 0.2565,
          0.3259, 0.2356, 0.2567, 0.1277, 0.1327, 0.2343, 0.2605, 0.2208,
          0.1317, 0.2082, 0.2037, 0.1961, 0.2377, 0.2394, 0.2137, 0.2721,
          0.2247, 0.1998, 0.2266, 0.2596, 0.1969, 0.2476, 0.2143, 0.2271,
          0.1905, 0.2329, 0.2307, 0.1727, 0.2581, 0.2139, 0.2581, 0.3042,
          0.2941, 0.3338, 0.3308, 0.4039, 0.3675, 0.3898, 0.3175, 0.2822,
          0.3720, 0.3534, 0.2870, 0.2013, 0.2042, 0.2333, 0.2184, 0.1713,
          0.3110, 0.2194, 0.1669, 0.1290, 0.1588, 0.2665, 0.2632, 0.2926,
          0.3841, 0.3920, 0.3265, 0.2872, 0.2563, 0.2793, 0.2583, 0.2047,
          0.2345, 0.2237, 0.2803, 0.2143, 0.2564, 0.2459, 0.1595, 0.1728,
          0.0720, 0.1554, 0.1326, 0.1406, 0.1600, 0.1543, 0.1987, 0.2054,
          0.1044, 0.0461, 0.0209, 0.1430, 0.0882, 0.0763, 0.1068, 0.1063,
          0.0913, 0.1145, 0.1811, 0.1464, 0.2581, 0.2745, 0.2519, 0.2473,
          0.2790, 0.2186, 0.1796, 0.2382, 0.2448, 0.2599, 0.2594, 0.1389,
          0.2243, 0.1304, 0.2592, 0.3102, 0.3076, 0.2815, 0.3319, 0.3251,
          0.2702, 0.3631, 0.3361, 0.2953, 0.2401, 0.2685, 0.2539, 0.2502,
          0.2625, 0.2840, 0.3066, 0.2858, 0.3792, 0.2239, 0.1970, 0.1844,
          0.2162, 0.2072, 0.1581, 0.1396, 0.1751, 0.1530, 0.1849, 0.1244,
          0.1356, 0.0595, 0.0719, 0.0992, 0.0712, 0.1391, 0.1548, 0.1226,
          0.1352, 0.1415, 0.1716, 0.1275, 0.1914, 0.0864, 0.0610, 0.0000,
          0.0314, 0.1350, 0.1067, 0.0844, 0.0415]]], device='cuda:0',
       grad_fn=<SubBackward0>)
tensor([[[inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]]],
       device='cuda:0')
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
tensor(17.2652, device='cuda:0', grad_fn=<AddBackward0>)
tensor(9.1867, device='cuda:0', grad_fn=<AddBackward0>)
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
tensor([inf, 1., inf, 1., inf, 1., inf, 1., 1., inf], grad_fn=<AddBackward0>)
tensor(inf, grad_fn=<SelectBackward>)
tensor(1., grad_fn=<SelectBackward>)
tensor(inf, grad_fn=<SelectBackward>)
tensor([inf, 1., inf, 1., inf, 1., inf, 1., 1., inf], grad_fn=<AddBackward0>)
tensor([-7.7934e+37,  4.5637e-41, -8.3782e+37,  4.5637e-41, -7.7930e+37,
         4.5637e-41, -7.7939e+37,  4.5637e-41, -7.7937e+37,  4.5637e-41])
tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
tensor([-3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.])
1
torch.Size([1, 1, 237])
torch.Size([1, 1, 237])
237
torch.Size([238])
tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,
         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,
         24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,
         36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,
         48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,
         60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,
         72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,
         84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,
         96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,
        108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.,
        120., 121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,
        132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,
        144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154., 155.,
        156., 157., 158., 159., 160., 161., 162., 163., 164., 165., 166., 167.,
        168., 169., 170., 171., 172., 173., 174., 175., 176., 177., 178., 179.,
        180., 181., 182., 183., 184., 185., 186., 187., 188., 189., 190., 191.,
        192., 193., 194., 195., 196., 197., 198., 199., 200., 201., 202., 203.,
        204., 205., 206., 207., 208., 209., 210., 211., 212., 213., 214., 215.,
        216., 217., 218., 219., 220., 221., 222., 223., 224., 225., 226., 227.,
        228., 229., 230., 231., 232., 233., 234., 235., 236.])
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
tensor([[[   inf,    inf,    inf,    inf,    inf,    inf,    inf,    inf,
             inf,    inf,    inf,    inf, 0.4637, 0.4715, 0.4283, 0.3958,
          0.2788, 0.2573, 0.2530, 0.1239, 0.0974, 0.1257, 0.0891, 0.0485,
          0.1402, 0.0870, 0.1221, 0.2019, 0.0838, 0.0778, 0.1854, 0.1001,
          0.1947, 0.1713, 0.1495, 0.2915, 0.3877, 0.4052, 0.2340, 0.3199,
          0.2766, 0.3577, 0.2350, 0.3728, 0.3560, 0.2619, 0.4013, 0.3119,
          0.2803, 0.2660, 0.2543, 0.2017, 0.3032, 0.2461, 0.2887, 0.3931,
          0.3941, 0.3507, 0.3224, 0.2945, 0.2742, 0.2643, 0.1116, 0.0784,
          0.0390, 0.1491, 0.1126, 0.2536, 0.2229, 0.1419, 0.2396, 0.2665,
          0.2536, 0.4562, 0.3216, 0.3077, 0.2989, 0.2979, 0.2182, 0.2600,
          0.2690, 0.1984, 0.2445, 0.2285, 0.2316, 0.2024, 0.1905, 0.2220,
          0.2405, 0.1580, 0.3338, 0.3099, 0.2568, 0.2299, 0.3214, 0.1382,
          0.2189, 0.1393, 0.1993, 0.2495, 0.1972, 0.1903, 0.1309, 0.1574,
          0.1863, 0.1846, 0.2229, 0.3138, 0.1789, 0.2535, 0.2923, 0.2764,
          0.2234, 0.1933, 0.1701, 0.2860, 0.2433, 0.3242, 0.1841, 0.2138,
          0.1351, 0.1172, 0.0861, 0.0000, 0.0454, 0.0887, 0.1269, 0.1564,
          0.1323, 0.2445, 0.1564, 0.0936, 0.1542, 0.2115, 0.0672, 0.0815,
          0.2203, 0.2683, 0.3169, 0.2569, 0.2590, 0.2644, 0.2477, 0.1448,
          0.1274, 0.1066, 0.1111, 0.1329, 0.2514, 0.1932, 0.1919, 0.1491,
          0.0782, 0.1743, 0.1999, 0.1160, 0.2221, 0.1715, 0.1674, 0.1080,
          0.0970, 0.0303, 0.1884, 0.1929, 0.1876, 0.1684, 0.2651, 0.1218,
          0.2526, 0.1620, 0.3615, 0.3352, 0.3264, 0.3316, 0.3334, 0.3475,
          0.3295, 0.2705, 0.2439, 0.0841, 0.2462, 0.2646, 0.2458, 0.1819,
          0.2016, 0.1626, 0.2317, 0.3193, 0.2510, 0.2054, 0.1432, 0.1614,
          0.1423, 0.1697, 0.1352, 0.0932, 0.1151, 0.1810, 0.1464, 0.0941,
          0.1486, 0.2024, 0.0811, 0.1905, 0.1920, 0.1880, 0.0902, 0.1694,
          0.1800, 0.1461, 0.1321, 0.1215, 0.1488, 0.1598, 0.1817, 0.0889,
          0.1935, 0.1011, 0.2219, 0.0794, 0.1479, 0.1784, 0.1909, 0.1107,
          0.2003, 0.1455, 0.2019, 0.1286, 0.1501, 0.1280, 0.1430, 0.1774,
          0.1385, 0.0929, 0.1683, 0.0396, 0.1427, 0.0065, 0.1671, 0.0950,
          0.2423, 0.3172, 0.3669, 0.2022, 0.3458, 0.3374, 0.2644, 0.2769,
          0.0191]]], device='cuda:0', grad_fn=<CatBackward>)
torch.Size([1, 1, 249])
torch.Size([237])
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
tensor([[[0.3128, 0.4144, 0.4980, 0.5470, 0.7312, 0.6488, 0.5883, 0.4881,
          0.2293, 0.2833, 0.4157, 0.5674, 0.5395, 0.4840, 0.5813, 0.4217,
          0.4572, 0.5814, 0.4644, 0.3353, 0.3866, 0.2310, 0.4093, 0.3461,
          0.3970, 0.3691, 0.4748, 0.4789, 0.4086, 0.5038, 0.4521, 0.3715,
          0.3544, 0.3791, 0.3536, 0.3859, 0.3652, 0.5139, 0.5096, 0.3612,
          0.3218, 0.3261, 0.4535, 0.2600, 0.4197, 0.4367, 0.5231, 0.4593,
          0.5101, 0.5229, 0.5599, 0.4873, 0.6202, 0.5335, 0.4347, 0.4742,
          0.4673, 0.5226, 0.4786, 0.4592, 0.5517, 0.5524, 0.5218, 0.3998,
          0.4665, 0.4013, 0.3671, 0.4827, 0.3909, 0.2418, 0.3256, 0.3598,
          0.4048, 0.4537, 0.5279, 0.4744, 0.4189, 0.5655, 0.5414, 0.3649,
          0.4961, 0.4577, 0.3398, 0.4074, 0.2933, 0.2582, 0.2889, 0.3407,
          0.3194, 0.4625, 0.5068, 0.5298, 0.5273, 0.5874, 0.4088, 0.4418,
          0.3887, 0.5501, 0.3993, 0.5350, 0.4878, 0.4025, 0.3221, 0.3664,
          0.3489, 0.4654, 0.3300, 0.2880, 0.4155, 0.3274, 0.2470, 0.2801,
          0.4126, 0.4448, 0.3833, 0.2427, 0.4051, 0.3270, 0.4552, 0.4522,
          0.2493, 0.3296, 0.3032, 0.4172, 0.3764, 0.2454, 0.3194, 0.3797,
          0.3377, 0.3506, 0.3089, 0.2636, 0.2741, 0.3518, 0.3879, 0.4597,
          0.3896, 0.2606, 0.3298, 0.3499, 0.4506, 0.4512, 0.4061, 0.3708,
          0.2781, 0.2460, 0.2674, 0.3433, 0.2887, 0.2460, 0.2861, 0.2107,
          0.2585, 0.2915, 0.4396, 0.4936, 0.3993, 0.3024, 0.4566, 0.5064,
          0.6282, 0.5670, 0.6158, 0.5640, 0.3456, 0.4694, 0.3534, 0.4783,
          0.4304, 0.4359, 0.3057, 0.4117, 0.4509, 0.4852, 0.6024, 0.5934,
          0.4675, 0.5487, 0.4625, 0.4392, 0.3993, 0.4195, 0.3558, 0.3566,
          0.2353, 0.2483, 0.3526, 0.2313, 0.2292, 0.1060, 0.1854, 0.3010,
          0.3213, 0.2707, 0.1308, 0.1187, 0.0950, 0.2081, 0.1771, 0.1438,
          0.0566, 0.0310, 0.0000, 0.1693, 0.1606, 0.2154, 0.1031, 0.1527,
          0.0782, 0.1494, 0.0872, 0.2707, 0.2441, 0.3530, 0.2678, 0.3373,
          0.3557, 0.3344, 0.2613, 0.2336, 0.4142, 0.3703, 0.4260, 0.5184,
          0.1979, 0.4137, 0.4272, 0.3233, 0.4512, 0.3876, 0.3507, 0.3429,
          0.3292, 0.3783, 0.4640, 0.4164, 0.2514]]], device='cuda:0',
       grad_fn=<SubBackward0>)
torch.Size([1, 1, 237])
torch.Size([1, 1, 237])
torch.Size([1, 1, 237])
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
torch.Size([189])
torch.Size([1, 1, 189])
tensor([[[0.0568, 0.0000, 0.0988, 0.1019, 0.1402, 0.2594, 0.1938, 0.2960,
          0.4559, 0.3994, 0.3109, 0.4830, 0.3457, 0.3995, 0.2895, 0.3858,
          0.4181, 0.3337, 0.3641, 0.4256, 0.3685, 0.4563, 0.4647, 0.3334,
          0.4393, 0.3540, 0.3820, 0.3681, 0.6145, 0.4189, 0.4551, 0.3865,
          0.3121, 0.3673, 0.4684, 0.4702, 0.4008, 0.5450, 0.4411, 0.4042,
          0.3591, 0.4434, 0.4785, 0.4208, 0.5056, 0.2390, 0.3058, 0.4171,
          0.3532, 0.3934, 0.4316, 0.4324, 0.4492, 0.4071, 0.4702, 0.4468,
          0.3461, 0.4801, 0.5234, 0.3512, 0.1274, 0.3630, 0.3836, 0.4249,
          0.3393, 0.4238, 0.3064, 0.3956, 0.4536, 0.5688, 0.3764, 0.2146,
          0.3690, 0.4961, 0.5015, 0.4326, 0.4771, 0.4506, 0.3950, 0.4853,
          0.3915, 0.3436, 0.3834, 0.2786, 0.3064, 0.3659, 0.4423, 0.4308,
          0.5535, 0.4932, 0.4620, 0.3844, 0.4176, 0.3482, 0.5020, 0.3023,
          0.4530, 0.4602, 0.4425, 0.3726, 0.3561, 0.3315, 0.2966, 0.3362,
          0.2412, 0.3421, 0.3860, 0.3291, 0.2960, 0.3538, 0.2890, 0.3481,
          0.3645, 0.3869, 0.3942, 0.4827, 0.5044, 0.4465, 0.5020, 0.5007,
          0.5537, 0.5631, 0.4776, 0.6459, 0.6307, 0.5679, 0.5197, 0.4113,
          0.5221, 0.4891, 0.4955, 0.5049, 0.5335, 0.5494, 0.5182, 0.5900,
          0.4075, 0.4891, 0.4073, 0.4445, 0.3653, 0.4853, 0.5064, 0.5700,
          0.6814, 0.4946, 0.4736, 0.4901, 0.3718, 0.4792, 0.5228, 0.4938,
          0.4187, 0.2680, 0.2987, 0.3710, 0.4123, 0.3924, 0.4231, 0.4981,
          0.5011, 0.4778, 0.5132, 0.4666, 0.3499, 0.4657, 0.4993, 0.4880,
          0.5085, 0.3096, 0.4460, 0.5516, 0.3974, 0.3582, 0.3998, 0.4855,
          0.4315, 0.4140, 0.3940, 0.3901, 0.5134, 0.3337, 0.4766, 0.4119,
          0.4386, 0.4209, 0.3874, 0.2939, 0.3432]]], device='cuda:0',
       grad_fn=<SubBackward0>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0054e+00,
        2.0687e+03, 7.9547e+08, 3.0602e+14, 1.1773e+20, 4.5290e+25, 1.7423e+31,
        6.7027e+36,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], grad_fn=<AddBackward0>)
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
tensor(8.5552, device='cuda:0', grad_fn=<AddBackward0>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0126e+00, 6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12,
        4.7522e+16, 2.4680e+20, 1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor(19.5115, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.5160, device='cuda:0', grad_fn=<SelectBackward>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0126e+00,
        6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12, 4.7522e+16, 2.4680e+20,
        1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor([-10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,
          2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,  13.,
         14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,
         26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,
         38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,  49.,
         50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,  60.,  61.,
         62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,
         74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,
         86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,
         98.,  99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,
        110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,
        122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132., 133.,
        134., 135., 136., 137., 138., 139., 140., 141., 142., 143., 144., 145.,
        146., 147., 148., 149., 150., 151., 152., 153., 154., 155., 156., 157.,
        158., 159., 160., 161., 162., 163., 164., 165., 166., 167., 168., 169.,
        170., 171., 172., 173., 174., 175., 176., 177., 178., 179., 180., 181.,
        182., 183., 184., 185., 186., 187., 188., 189., 190., 191., 192., 193.,
        194., 195., 196., 197., 198., 199., 200., 201., 202., 203., 204., 205.,
        206., 207., 208., 209., 210., 211., 212., 213., 214., 215., 216., 217.,
        218., 219., 220., 221., 222., 223., 224., 225., 226.], device='cuda:0')
tensor([       inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf, 1.7955e+35,
        3.4572e+31, 6.6568e+27, 1.2818e+24, 2.4680e+20, 4.7522e+16, 9.1504e+12,
        1.7619e+09, 3.3926e+05, 6.6324e+01, 1.0126e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0126e+00,
        6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12, 4.7522e+16, 2.4680e+20,
        1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor(19.5115, device='cuda:0', grad_fn=<AddBackward0>)
tensor([       inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf, 1.7955e+35,
        3.4572e+31, 6.6568e+27, 1.2818e+24, 2.4680e+20, 4.7522e+16, 9.1504e+12,
        1.7619e+09, 3.3926e+05, 6.6324e+01, 1.0126e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0126e+00,
        6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12, 4.7522e+16, 2.4680e+20,
        1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
39
tensor(19.5115, device='cuda:0', grad_fn=<AddBackward0>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0126e+00, 6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12,
        4.7522e+16, 2.4680e+20, 1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor(0.5160, device='cuda:0', grad_fn=<SelectBackward>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0126e+00, 6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12,
        4.7522e+16, 2.4680e+20, 1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
torch.Size([237])
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0126e+00, 6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12,
        4.7522e+16, 2.4680e+20, 1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0126e+00, 6.6324e+01, 3.3926e+05, 1.7619e+09, 9.1504e+12,
        4.7522e+16, 2.4680e+20, 1.2818e+24, 6.6568e+27, 3.4572e+31, 1.7955e+35,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
tensor([4.0465e-01, 3.7386e-01, 4.2260e-01, 4.2522e-01, 4.8924e-01, 4.3695e-01,
        5.6862e-01, 4.5163e-01, 2.8887e+04, 1.5141e+11, 9.6697e+17, 5.6149e+24,
        2.9297e+31, 1.3395e+38,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        nan,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<MulBackward0>)
tensor([], device='cuda:0', grad_fn=<SliceBackward>)
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
1
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.3675e+04, 1.5725e+14, 1.8084e+24,
        2.0797e+34,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
torch.Size([1])
tensor([0.4889, 0.3054], device='cuda:0', grad_fn=<SliceBackward>)
tensor(0.3054, device='cuda:0', grad_fn=<MinBackward1>)
tensor(1, device='cuda:0')
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
Brand new model

--------------------------- EPOCH:1/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
[tensor(0.6510, device='cuda:0', grad_fn=<SelectBackward>)]
tensor([2.9812e-01, 5.0624e-01, 6.1191e-01, 7.3576e-01, 7.7215e-01, 7.4633e-01,
        7.4920e-01, 5.9249e-01, 5.6894e-01, 5.4690e-01, 4.7628e-01, 4.7284e-01,
        4.1338e-01, 4.3991e-01, 3.3494e-01, 2.7884e-01, 2.8065e-01, 3.3390e-01,
        7.9451e+00, 7.2735e+03, 7.0048e+06, 7.1935e+09, 4.2106e+12, 3.3651e+15,
        1.6865e+18, 1.9412e+21, 2.0479e+24, 1.4254e+27, 1.9591e+30, 1.1857e+33,
        9.5729e+35,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        nan,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<MulBackward0>)
1
0.50624
tensor(0.1963, device='cuda:0', grad_fn=<SelectBackward>)
3
tensor(16.4768, device='cuda:0', grad_fn=<AddBackward0>)
tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0001e+00, 1.0411e+00,
        3.4174e+01, 2.6752e+04, 2.1572e+07, 1.7396e+10, 1.4028e+13, 1.1312e+16,
        9.1218e+18, 7.3558e+21, 5.9317e+24, 4.7833e+27, 3.8572e+30, 3.1104e+33,
        2.5082e+36,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor([0.2981, 0.5062], device='cuda:0', grad_fn=<SliceBackward>)
tensor([[[0.6510, 0.8591, 0.9648, 1.0887, 1.1250, 1.0992, 1.1021, 0.9454,
          0.9218, 0.8998, 0.8292, 0.8257, 0.7663, 0.7928, 0.6878, 0.6317,
          0.6335, 0.6736, 0.5854, 0.6248, 0.6776, 0.7664, 0.6531, 0.6504,
          0.5378, 0.6168, 0.6981, 0.6509, 0.8608, 0.7341, 0.7346, 0.6432,
          0.5482, 0.7075, 0.5716, 0.4850, 0.6351, 0.8203, 0.6044, 0.6095,
          0.6838, 0.5984, 0.7887, 0.8639, 0.9823, 0.8971, 0.8330, 0.9565,
          1.0280, 0.9233, 0.8510, 0.8569, 1.0058, 0.7705, 0.6431, 0.7106,
          0.7713, 0.8507, 0.8125, 0.6525, 0.7120, 0.7457, 0.8246, 0.8118,
          0.3982, 0.6118, 0.6174, 0.5448, 0.6581, 0.7303, 0.4339, 0.4794,
          0.5197, 0.5372, 0.7670, 0.7963, 0.9107, 0.7987, 0.8302, 0.8665,
          0.8895, 0.7154, 0.7823, 0.6088, 0.5478, 0.6115, 0.6567, 0.5201,
          0.5531, 0.5137, 0.3982, 0.7250, 0.6534, 0.7717, 0.9177, 0.7174,
          0.6352, 0.8639, 0.6302, 0.5235, 0.7509, 0.8070, 0.8452, 0.9461,
          0.7595, 0.7172, 0.7173, 0.7184, 0.8946, 0.8424, 0.7610, 0.6442,
          0.7676, 0.8473, 0.7497, 0.7884, 0.6686, 0.8375, 0.7171, 0.3903,
          0.3808, 0.5553, 0.6682, 0.6171, 0.6389, 0.7158, 0.6307, 0.6720,
          0.6836, 0.5008, 0.5073, 0.3529, 0.7507, 0.7804, 0.9263, 0.8884,
          0.7278, 0.3583, 0.3655, 0.6266, 0.7892, 0.8432, 0.6556, 0.5767,
          0.5519, 0.6354, 0.4754, 0.5106, 0.4596, 0.3606, 0.4536, 0.3559,
          0.5346, 0.6396, 0.7862, 0.7722, 0.7414, 0.6625, 0.6537, 0.7713,
          0.8200, 0.7927, 0.8388, 0.9244, 0.9929, 0.8961, 0.8667, 0.8417,
          0.6946, 0.5226, 0.4744, 0.5198, 0.6477, 0.5959, 0.6408, 0.6999,
          0.6285, 0.5137, 0.5165, 0.7279, 0.6278, 0.6674, 0.7154, 0.6819,
          0.7946, 0.6718, 0.8185, 0.5350, 0.5892, 0.6787, 0.8002, 0.6016,
          0.6620, 0.7236, 0.5909, 0.7208, 0.7809, 0.6488, 0.4682, 0.6079,
          0.3793, 0.4642, 0.4926, 0.5511, 0.4943, 0.4758, 0.4907, 0.4785,
          0.5095, 0.6383, 0.7191, 0.6575, 0.5472, 0.4218, 0.3788, 0.5370,
          0.5489, 0.6349, 0.5620, 0.6484, 0.7071, 0.5177, 0.6773, 0.6849,
          0.6199, 0.6851, 0.8714, 1.0311, 0.8399, 0.8493, 0.7874, 0.6978,
          0.6521, 0.6635, 0.6027, 0.7754, 0.8657]]], device='cuda:0',
       grad_fn=<UnsqueezeBackward0>)
[tensor(0.6510, device='cuda:0', grad_fn=<SelectBackward>)]
20
tensor([1.7396e+10, 2.1572e+07, 2.6752e+04, 3.4174e+01, 1.0411e+00, 1.0001e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0001e+00,
        1.0411e+00, 3.4174e+01, 2.6752e+04, 2.1572e+07, 1.7396e+10, 1.4028e+13,
        1.1312e+16, 9.1218e+18, 7.3558e+21, 5.9317e+24, 4.7833e+27, 3.8572e+30,
        3.1104e+33, 2.5082e+36,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor([1.7396e+10, 2.1572e+07, 2.6752e+04, 3.4174e+01, 1.0411e+00, 1.0001e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0001e+00,
        1.0411e+00, 3.4174e+01, 2.6752e+04, 2.1572e+07, 1.7396e+10, 1.4028e+13,
        1.1312e+16, 9.1218e+18, 7.3558e+21, 5.9317e+24, 4.7833e+27, 3.8572e+30,
        3.1104e+33, 2.5082e+36,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<AddBackward0>)
tensor(6.6926, device='cuda:0', grad_fn=<AddBackward0>)
tensor(16.4768, device='cuda:0', grad_fn=<AddBackward0>)
tensor([5.1860e+09, 1.0921e+07, 1.6370e+04, 2.5144e+01, 8.0391e-01, 7.4637e-01,
        7.4920e-01, 5.9249e-01, 5.6894e-01, 5.4690e-01, 4.7628e-01, 4.7284e-01,
        4.1338e-01, 4.3991e-01, 3.3494e-01, 2.7884e-01, 2.8064e-01, 3.2070e-01,
        2.3249e-01, 2.7188e-01, 3.2472e-01, 4.1352e-01, 3.0016e-01, 2.9748e-01,
        1.8488e-01, 2.6390e-01, 3.4524e-01, 2.9799e-01, 5.0790e-01, 3.8120e-01,
        3.8166e-01, 2.9034e-01, 1.9528e-01, 3.5458e-01, 2.1871e-01, 1.3207e-01,
        2.9381e-01, 1.5973e+01, 6.7275e+03, 5.5346e+06, 5.7560e+09, 3.4439e+12,
        4.9295e+15, 4.6611e+18, 4.6295e+21, 3.2278e+24, 2.2962e+27, 2.3282e+30,
        2.0999e+33, 1.4307e+36,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        nan,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf], device='cuda:0',
       grad_fn=<MulBackward0>)
torch.Size([21])
tensor(18, device='cuda:0')
