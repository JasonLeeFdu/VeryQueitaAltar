=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
The model has been trained in Epoch:1345, GlobalIteration:59224
Model Path:/home/winston/workSpace/PycharmProjects/VQA/Ours/Models/VQA_Baseline3_0/model/model_1345_44.mdl

--------------------------- EPOCH:1346/4000 ---------------------------
Iter: 0, Loss: 0.048220
Iter: 10, Loss: 0.049016
Iter: 20, Loss: 0.075614
Iter: 30, Loss: 0.061099
Iter: 40, Loss: 0.035509
--------------------------- EPOCH:1347/4000 ---------------------------
Iter: 0, Loss: 0.053418
Iter: 10, Loss: 0.074777
Iter: 20, Loss: 0.054073
Iter: 30, Loss: 0.031136
Iter: 40, Loss: 0.037265
--------------------------- EPOCH:1348/4000 ---------------------------
Iter: 0, Loss: 0.044148
Iter: 10, Loss: 0.066477
Iter: 20, Loss: 0.033888
Iter: 30, Loss: 0.049167
Iter: 40, Loss: 0.048382
--------------------------- EPOCH:1349/4000 ---------------------------
Iter: 0, Loss: 0.027609
Iter: 10, Loss: 0.049511
Iter: 20, Loss: 0.048795
Iter: 30, Loss: 0.051566
Iter: 40, Loss: 0.049848
--------------------------- EPOCH:1350/4000 ---------------------------
Iter: 0, Loss: 0.065093
Iter: 10, Loss: 0.055573
Iter: 20, Loss: 0.036014
Iter: 30, Loss: 0.028581
Iter: 40, Loss: 0.034383
--------------------------- EPOCH:1351/4000 ---------------------------
Iter: 0, Loss: 0.065781
Iter: 10, Loss: 0.042244
Iter: 20, Loss: 0.048496
Iter: 30, Loss: 0.037795
Iter: 40, Loss: 0.037084
--------------------------- EPOCH:1352/4000 ---------------------------
Iter: 0, Loss: 0.038866
Iter: 10, Loss: 0.026596
Iter: 20, Loss: 0.042023
Iter: 30, Loss: 0.057408
Iter: 40, Loss: 0.037479
--------------------------- EPOCH:1353/4000 ---------------------------
Iter: 0, Loss: 0.084413
Iter: 10, Loss: 0.054825
Iter: 20, Loss: 0.071130
Iter: 30, Loss: 0.045555
Iter: 40, Loss: 0.063347
--------------------------- EPOCH:1354/4000 ---------------------------
Iter: 0, Loss: 0.038766
Iter: 10, Loss: 0.067997
Iter: 20, Loss: 0.030339
Iter: 30, Loss: 0.057505
Iter: 40, Loss: 0.047100
--------------------------- EPOCH:1355/4000 ---------------------------
Iter: 0, Loss: 0.045441
Iter: 10, Loss: 0.052610
Iter: 20, Loss: 0.030367
Iter: 30, Loss: 0.064081
Iter: 40, Loss: 0.041400
--------------------------- EPOCH:1356/4000 ---------------------------
Iter: 0, Loss: 0.043103
Iter: 10, Loss: 0.041440
Iter: 20, Loss: 0.042776
Iter: 30, Loss: 0.080350
Iter: 40, Loss: 0.052106
--------------------------- EPOCH:1357/4000 ---------------------------
Iter: 0, Loss: 0.038438
Iter: 10, Loss: 0.047119
Iter: 20, Loss: 0.034329
Iter: 30, Loss: 0.050892
Iter: 40, Loss: 0.042059
--------------------------- EPOCH:1358/4000 ---------------------------
Iter: 0, Loss: 0.036126
Iter: 10, Loss: 0.036644
Iter: 20, Loss: 0.022569
Iter: 30, Loss: 0.046094
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
The model has been trained in Epoch:1357, GlobalIteration:59752
Model Path:/home/winston/workSpace/PycharmProjects/VQA/Ours/Models/VQA_Baseline3_0/model/model_1357_44.mdl

--------------------------- EPOCH:1358/4000 ---------------------------
tensor([[[1.3617, 1.7251, 1.6039, 1.5584, 1.4936, 1.5088, 1.5557, 1.5407,
          1.3803, 1.4282, 1.3472, 1.2969, 1.3581, 1.3649, 1.3306, 1.3288,
          1.2683, 1.2456, 1.2953, 1.1810, 1.2399, 1.1809, 1.1807, 1.2452,
          1.2510, 1.1388, 1.2062, 1.1029, 1.0936, 1.0335, 1.1119, 1.1658,
          1.1629, 1.2085, 1.1853, 1.1566, 1.1679, 1.1701, 1.2129, 1.2326,
          1.2107, 1.0806, 1.0001, 1.0455, 1.1137, 1.1808, 1.0956, 1.1513,
          1.1230, 1.0978, 1.0529, 0.9653, 0.8958, 1.0096, 0.9367, 1.0395,
          1.0390, 0.8805, 0.8998, 0.8907, 0.7967, 0.7681, 0.8103, 0.9546,
          0.9708, 1.0452, 1.0470, 1.0350, 0.9889, 0.9890, 0.9423, 1.0407,
          0.9922, 1.0324, 0.9654, 0.8795, 0.8341, 0.9298, 0.8605, 0.9317,
          0.8731, 0.9536, 0.8635, 1.0048, 0.9289, 1.0110, 0.8610, 0.9116,
          0.7617, 0.9200, 0.9244, 0.8826, 0.8614, 0.9296, 0.8466, 0.8631,
          0.8852, 0.8766, 0.8219, 0.8331, 0.7344, 0.7250, 0.7794, 0.6617,
          0.7441, 0.8310, 0.7728, 0.8559, 0.8656, 0.9265, 0.9405, 0.9623,
          0.8868, 0.8541, 0.8505, 0.7553, 0.8512, 0.8356, 0.9127, 0.8427,
          0.8697, 0.8395, 0.8025, 0.8118, 0.8106, 0.7964, 0.7896, 0.7344,
          0.8230, 0.8049, 0.7766, 0.8539, 0.8076, 0.7591, 0.8131, 0.8513,
          0.8248, 0.8287, 0.8209, 0.7543, 0.7924, 0.7526, 0.7534, 0.7009,
          0.7516, 0.6681, 0.7681, 0.6910, 0.7333, 0.7125, 0.6888, 0.7996,
          0.7711, 0.8048, 0.7931, 0.7999, 0.7065, 0.6912, 0.7074, 0.6175,
          0.6226, 0.6023, 0.6563, 0.5974, 0.5408, 0.5483, 0.6021, 0.5553,
          0.4842, 0.4694, 0.4626, 0.4413, 0.3907, 0.4323, 0.4825, 0.4038,
          0.3884, 0.3323, 0.3035, 0.4070, 0.4186, 0.3924, 0.3797, 0.3676,
          0.2994, 0.3306, 0.3540, 0.3647, 0.3515]]], device='cuda:0',
       grad_fn=<UnsqueezeBackward0>)
torch.Size([1, 1, 189])
tensor(22.7742, device='cuda:0', grad_fn=<AddBackward0>)
tensor(23., device='cuda:0', grad_fn=<RoundBackward>)
tensor(22.7742, device='cuda:0', grad_fn=<AddBackward0>)
tensor(22, device='cuda:0', dtype=torch.int32)
tensor([[[1.3617, 1.7251, 1.6039, 1.5584, 1.4936, 1.5088, 1.5557, 1.5407,
          1.3803, 1.4282, 1.3472, 1.2969, 1.3581, 1.3649, 1.3306, 1.3288,
          1.2683, 1.2456, 1.2953, 1.1810, 1.2399, 1.1809, 1.1807, 1.2452,
          1.2510, 1.1388, 1.2062, 1.1029, 1.0936, 1.0335, 1.1119, 1.1658,
          1.1629, 1.2085, 1.1853, 1.1566, 1.1679, 1.1701, 1.2129, 1.2326,
          1.2107, 1.0806, 1.0001, 1.0455, 1.1137, 1.1808, 1.0956, 1.1513,
          1.1230, 1.0978, 1.0529, 0.9653, 0.8958, 1.0096, 0.9367, 1.0395,
          1.0390, 0.8805, 0.8998, 0.8907, 0.7967, 0.7681, 0.8103, 0.9546,
          0.9708, 1.0452, 1.0470, 1.0350, 0.9889, 0.9890, 0.9423, 1.0407,
          0.9922, 1.0324, 0.9654, 0.8795, 0.8341, 0.9298, 0.8605, 0.9317,
          0.8731, 0.9536, 0.8635, 1.0048, 0.9289, 1.0110, 0.8610, 0.9116,
          0.7617, 0.9200, 0.9244, 0.8826, 0.8614, 0.9296, 0.8466, 0.8631,
          0.8852, 0.8766, 0.8219, 0.8331, 0.7344, 0.7250, 0.7794, 0.6617,
          0.7441, 0.8310, 0.7728, 0.8559, 0.8656, 0.9265, 0.9405, 0.9623,
          0.8868, 0.8541, 0.8505, 0.7553, 0.8512, 0.8356, 0.9127, 0.8427,
          0.8697, 0.8395, 0.8025, 0.8118, 0.8106, 0.7964, 0.7896, 0.7344,
          0.8230, 0.8049, 0.7766, 0.8539, 0.8076, 0.7591, 0.8131, 0.8513,
          0.8248, 0.8287, 0.8209, 0.7543, 0.7924, 0.7526, 0.7534, 0.7009,
          0.7516, 0.6681, 0.7681, 0.6910, 0.7333, 0.7125, 0.6888, 0.7996,
          0.7711, 0.8048, 0.7931, 0.7999, 0.7065, 0.6912, 0.7074, 0.6175,
          0.6226, 0.6023, 0.6563, 0.5974, 0.5408, 0.5483, 0.6021, 0.5553,
          0.4842, 0.4694, 0.4626, 0.4413, 0.3907, 0.4323, 0.4825, 0.4038,
          0.3884, 0.3323, 0.3035, 0.4070, 0.4186, 0.3924, 0.3797, 0.3676,
          0.2994, 0.3306, 0.3540, 0.3647, 0.3515]]], device='cuda:0',
       grad_fn=<SliceBackward>)
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
The model has been trained in Epoch:1357, GlobalIteration:59752
Model Path:/home/winston/workSpace/PycharmProjects/VQA/Ours/Models/VQA_Baseline3_0/model/model_1357_44.mdl

--------------------------- EPOCH:1358/4000 ---------------------------
=============================== 本次训练信息 ==============================
实验模型名称: Baseline3_0
数据集KoNViD
模型名称Baseline3_0
==========================================================================
The model has been trained in Epoch:1357, GlobalIteration:59752
Model Path:/home/winston/workSpace/PycharmProjects/VQA/Ours/Models/VQA_Baseline3_0/model/model_1357_44.mdl

--------------------------- EPOCH:1358/4000 ---------------------------
Python 3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) 
[GCC 7.3.0] on linux
tensor([-1.1696e+00, -1.3780e+00, -1.3794e+00, -1.2068e+00, -1.1632e+00,
        -1.1262e+00, -1.1912e+00, -1.1957e+00, -1.2348e+00, -1.2260e+00,
        -1.0236e+00, -9.8265e-01, -9.6157e-01, -1.0450e+00, -1.0305e+00,
        -8.7510e-01, -8.6095e-01, -8.6715e-01, -9.2002e-01, -9.1367e-01,
        -1.0114e+00, -9.9319e-01, -9.0083e-01, -8.9108e-01, -8.7106e-01,
        -8.2131e-01, -8.3865e-01, -7.7582e-01, -7.9915e-01, -9.4086e-01,
        -9.4845e-01, -9.5396e-01, -9.8927e-01, -1.0112e+00, -1.0057e+00,
        -1.0115e+00, -9.9701e-01, -9.9482e-01, -9.7131e-01, -9.2900e-01,
        -9.0171e-01, -9.7876e-01, -9.8641e-01, -9.9757e-01, -9.2111e-01,
        -9.1749e-01, -1.0397e+00, -1.0210e+00, -1.0427e+00, -1.0222e+00,
        -9.0433e-01, -9.2471e-01, -9.2633e-01, -9.8743e-01, -9.0593e-01,
        -9.0263e-01, -8.9727e-01, -8.9710e-01, -1.0075e+00, -9.7996e-01,
        -9.7139e-01, -8.2030e-01, -7.3886e-01, -6.3092e-01, -6.1319e-01,
        -6.0712e-01, -6.1125e-01, -7.2765e-01, -7.4786e-01, -7.2684e-01,
        -7.1107e-01, -6.9315e-01, -7.4269e-01, -7.2203e-01, -7.2568e-01,
        -7.5509e-01, -7.8185e-01, -8.2073e-01, -8.5005e-01, -8.5559e-01,
        -8.4534e-01, -6.6057e-01, -6.4664e-01, -6.3834e-01, -7.1786e-01,
        -7.3413e-01, -7.5082e-01, -7.3333e-01, -5.6580e-01, -5.4603e-01,
        -5.5049e-01, -8.0478e-01, -7.8356e-01, -7.3270e-01, -7.4397e-01,
        -7.1952e-01, -6.9264e-01, -7.0867e-01, -6.8561e-01, -6.8790e-01,
        -7.1271e-01, -7.0155e-01, -6.6782e-01, -6.3827e-01, -6.7563e-01,
        -7.4498e-01, -7.4575e-01, -7.5102e-01, -7.7723e-01, -7.9108e-01,
        -8.4325e-01, -8.5746e-01, -8.1016e-01, -7.9907e-01, -7.6042e-01,
        -7.2561e-01, -7.3580e-01, -7.5701e-01, -7.7446e-01, -7.8871e-01,
        -7.9291e-01, -8.0676e-01, -7.6404e-01, -7.9395e-01, -7.8755e-01,
        -7.9009e-01, -7.9457e-01, -6.6094e-01, -6.5950e-01, -7.2626e-01,
        -7.3034e-01, -7.6909e-01, -7.2075e-01, -6.7991e-01, -6.6841e-01,
        -6.0895e-01, -2.1657e-01, -1.8560e-01, -1.9298e-01, -4.3984e-01,
        -4.4027e-01, -3.8967e-01, -3.8442e-01, -5.2966e-01, -5.3221e-01,
        -5.1499e-01, -5.7506e-01, -4.7338e-01, -3.3942e-01, -3.4599e-01,
        -4.2918e-01, -4.4374e-01, -4.6066e-01, -5.2077e-01, -5.1556e-01,
        -6.0913e-01, -6.3072e-01, -6.4649e-01, -6.5121e-01, -6.6675e-01,
        -7.6043e-01, -7.4645e-01, -6.6003e-01, -6.8835e-01, -7.0002e-01,
        -7.0886e-01, -6.9721e-01, -7.0828e-01, -7.0309e-01, -7.1642e-01,
        -7.3519e-01, -7.3948e-01, -7.4255e-01, -7.3996e-01, -7.5575e-01,
        -7.3880e-01, -7.1604e-01, -5.6563e-01, -6.0327e-01, -5.9481e-01,
        -6.3340e-01, -7.0163e-01, -6.9767e-01, -7.0654e-01, -8.0123e-01,
        -7.8243e-01, -6.2315e-01, -6.0609e-01, -5.9653e-01, -6.2404e-01,
        -6.1005e-01, -5.6755e-01, -5.7541e-01, -6.4901e-01, -6.4789e-01,
        -6.3640e-01, -5.6059e-01, -5.5407e-01, -5.7187e-01, -5.7544e-01,
        -5.5831e-01, -5.6946e-01, -5.4820e-01, -5.2582e-01, -5.1781e-01,
        -4.6385e-01, -4.6412e-01, -4.6233e-01, -4.8283e-01, -4.7994e-01,
        -4.4738e-01, -4.2048e-01, -3.6546e-01, -2.6517e-01, -2.5973e-01,
        -2.6100e-01, -2.4152e-01, -2.4217e-01, -2.3943e-01, -2.2090e-01,
        -3.2276e-01, -3.1778e-01, -2.8087e-01, -2.5638e-01, -1.5319e-01,
        -1.6395e-01, -1.4183e-01, -1.6458e-01, -1.4364e-01, -2.1590e-01,
        -1.9264e-01, -1.8643e-01, -6.2659e-02, -6.3935e-02,  2.3886e-02,
        -4.4549e-04, -1.4523e-01], device='cuda:0', grad_fn=<SqueezeBackward0>)
